SYSTEM OVERVIEW (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

Architecture Reference (covered)
of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

Plain-English Notes (partial)
is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

DAY-1 SURVIVAL CHECKLIST (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

DEPLOYMENT & ROLLBACK (covered)
through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

COMMON FAILURES & FIXES (covered)
through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

KNOWN BAD DAYS / WINDOWS (covered)
through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

DANGER ZONES (DO NOT TOUCH) (covered)
through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

OWNERSHIP & ESCALATION (covered)
SYSTEM OVERVIEW (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

FIRST 30-DAY OWNERSHIP PLAN (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

OPEN RESPONSIBILITIES & TRANSITION PLAN (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

I need. I think this is enough. Last thing. Continue. Good application. Please feel free to reach. To me and test the application as well as possible. Let me know if you can help me improve it. Thank you so much.

HANDOVER COMPLETION CHECK (covered)
So, hi everyone. Today this KT is about DevOps. We will be discussing how we can optimize the KT and how we can make it easy for everybody who is giving or who is taking the handover. So, there would be no gaps. Like anybody who is taking the place can take up a task from day one. So, let us start. Let me start with the system over overview and the system in pipelines. The system name is cloud native order processing platform. So, what does the system do in non-technical terms? This system handles order intake validation, pay-bin orchestration and fulfillment triggers. Who uses it? It is used by B2C users through the web app, B2B platform partners

through APIs. And also it turn out teams like finance and support. This system is not critical during business hours. So, this system is most critical during business hours, specifically during peak sales event. The business impact of the system is done is very high. Revenue loss, customer dissatisfaction and potential compliance issue. The worst case failure scenario is orders being accepted but not processed, which leads to financial reconciliation problems. We will be talking about business purpose and criticality. Now, come into the business purpose of problem. This system is always reliable, scalable, order processing across multiple sales channels. The reason why the business depends on it is that every revenue generating flow passes through this platform. In terms

of business criticality, this system is high. If the system is done, what breaks? Order placement breaks, payment confirmation stops, downstream fulfillment is blocked. Who is affected? Customers, finance teams, warehouse operation and leaders dashboards. Second, third part, we will be discussing about this environment and technologies. Let's talk about environments. We have broad staging, QA and Dev environments. Dev dev adopts own broads and staging while Dev and QA are most supported environments. Now, the key technologies used here includes AWS as the cloud provider. QBritis for container orchestration, terraform for infrastructure provisioning, Jenkins for CSD pipeline. These tools together form the core cloud platform and tooling this, tooling for the system. Architecture reference, for the architecture reference, there

is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

On day one, there are safe to use as redowning. The first safe actions you should perform are redowning checks, pipeline view in Jenkins, dashboard review in monitoring, dry running terraform. Action actions not to perform initially includes running terraform applying prod, editing any kinds of secrets, restarting Kubernetes services blind. Deploying process lets move to the normal deployment process. The exact steps are as follows. Step one, code is merged into main branch, step two, Jenkins pipeline triggers automatically. Step three, artifacts are built and deployed in Kubernetes. The repo link and pipeline links are documented. The trigger type is auto for non-trod and manual for prod. The deployment window is outside peak business hours. Pre-deployment checks includes pipeline

green status and no active incidents. Post deployment validation includes health checks and system at synthetic monitoring. Rollback procedure. If something goes wrong, here is the rollback procedure. The rollback procedure is failed. The rollback trigger is failed. Hel checks on or increase errors rate. Let me help it again. The rollback trigger is failed. Hel checks or increase error rate. The rollback action is rewarding the health release. The risk level is medium-f10 within 10 minutes. Who approves rollback? The on call lead or engineering managers. The expected roll time should be under 15 minutes and is expected to be under 15 minutes. Some common issues, failures and fixes which we do. A common issue in prod. Common issue

is prod crashing. The common issue is prod crashing looping. Due to miscontrigued and normal variables, misconfigured environment variables. The likely cause is missing secrets and the fix is validating the secret locations. In terms of frequency, this is medium. Now, known bad-design windows. High traffic during peak sales, month and then EOD. Audit window. During this time, deployment must be avoided. The danger zone. EAS should not touch include production, teleform, state files. As it can impact the production system. The Kubernetes cluster auto-skiller setting. These are dangerous because they can cause system bite outages. Approval is required and this actions are emergency only. If unsure do not proceed in escalating. Ownership and escalation. For ownership and escalation, the

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

the call. If you have any concerns of an task and if you don't want to take up any tasks, you are free to choose. Next is, hand-work completion. The replacements can deploy safely. The replacement. Understandable back. The replacement. No danger zones. Asclicion paths are clear. Architect is verified by the owner. This is the small overview which we planned. This is a small Katie sample Katie. Which I will be using is my first Katie planner continuum application. I hope this video is sufficient for my application to filter the changes. Get all the necessary words which I spoke just now. In 10 minutes video it should filter out and put it into the context of the template

Sign-off (covered)
is a detailed architectural documentation available. The link is maintained in a confluence page, which I will share in some time. The document was last updated last quarter and have been verified by the incoming owner as part of the KT. I strongly recommend that viewing the architecture diagram before touching production. Some plain English notes and tribal knowledge. There are some shortcuts in non-trod that does not exist in plot. When sharp edges that manual changes in AWS can drift terraform state file. Historically, this system had scaling issues during flash sales, soby cautious during traffic spikes. Devons are well-checked. Now, the Devons are well-checked. Requires access including cloud console access, git repository access, CSD tool, monitoring, secret location.

order services owned by the platform team. Devops should be contacted during deployment or incidents. The escalation channel is the on-call selection. Right. The first 30-day ownership plan is observe. We can be observed, shadow and redone. We can learn to change it. Pro-deployment with supervision independent ownership. In 4th week. Recording open responsibility in transition plan. Only existing and in progress tasks are handed over. No new initiatives. The incoming owner can accept different or reject tasks. It's up to the upcoming owners. If you comfortable take a task, then only say yes. There is state for what he say no. Because this Katie will take care of it. It will have a proof that what you told in

Missing Required